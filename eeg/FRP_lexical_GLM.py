#%%
import mne
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import glob
import os
import meegkit
from mne.datasets import sample
# from mne.stats.regression import linear_regression_raw
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
import scipy
from functools import partial
from mne_custom_regression import linear_regression_raw
import seaborn as sns
sns.set_palette("tab10")


#%% paths
dir_raw = '/Volumes/Blue1TB/EyeMindLink/Data'
dir_fif = '/Volumes/Blue1TB/EEG_processed/preprocessed_fif/'
event_fn_suffix = '_eyetracker_events.csv' # inside dir_fif, events containing fixations sacs and blinks as well as tasks, generated by merge_eyetracker_eeg.py
dir_out = '/Volumes/Blue1TB/EEG_processed/FRP_TRF_lexical_justwordfix_dummy/'
# this version uses dummy coding for MW: intercept is FRP, MW=-1 and MW=0 are additional predictors
# there will be separate columsn for each MW and lexical covariate


os.makedirs(dir_out, exist_ok=True)
dir_events = os.path.expanduser('~/Emotive Computing Dropbox/Rosy Southwell/EyeMindLink/Processed/events/') # task events
ia_df = pd.read_csv('../info/ia_label_mapping_opt_surprisal.csv').rename(columns={'gpt2_surprisal_page':'surprisal'})
# remove punctuation from IA_ID
ia_df = ia_df.loc[~ia_df['punctuation']]
ia_df['IA_ID'] = ia_df['IA_ID'].fillna('-1').astype(float).astype(int)
ia_df['log_word_freq'] = ia_df['word_freq'].astype(float).apply(np.log).replace(-np.inf, np.nan)

beh_df = pd.read_csv('~/Emotive Computing Dropbox/Rosy Southwell/EyeMindLink/Processed/Behaviour/EML1_page_level.csv') # comp and MW scores
eeg_trigger_df = pd.read_csv('../info/EEGtriggerSources.csv')
fn_base = '_p.fif'

pIDs = [re.findall(r'EML1_\d{3}', f)[0] for f in os.listdir(dir_fif) if f.endswith(fn_base)]
# unique and sort
pIDs = sorted(list(set(pIDs)))
exclude = [20, 21, 22, 23, 24, 25, 26, 27, 31, 39, 40, 73, 77, 78, 87,88,93,99, 
    110,115,123,125, 138, 160, 164,167,168, 170,171,172,173, 175,176,177, 178,179] # ubj to exclude because no eeg or no trigger etc.
pIDs = [p for p in pIDs if int(re.findall(r'\d{3}', p)[0]) not in exclude]
# pIDs=['EML1_028']
REDO = True
channels = ['CPz', 'FCz', 'AFF5h', 'AFF6h', 'CCP5h', 'CCP6h', 'PPO9h', 'PPO10h']

# wrap solver in a function to make it a callable
def ridge_solver(X, y, alpha=1): 
    res = Ridge(solver='auto',alpha=alpha).fit(X, y).coef_ #TODO: what else comes from Ridge
    if len(res.shape)==1:
        res = np.expand_dims(res, axis=0)
    return res

#%% Loop over subjects
if REDO:
    rERP_ALL = []
    for pID in pIDs: 
        try:
            mne.set_log_level('WARNING')
            ##### load 
            EEG = mne.io.read_raw_fif(os.path.join(dir_fif, f'{pID}_p.fif'), preload=True)
            # check all channels are present
            print(EEG.ch_names)
            if set(channels).isdisjoint(EEG.ch_names):
                print(f'{pID} does not contain all channels, skipping')
                raise Exception(f'{pID} does not contain all channels, skipping')
            events = pd.read_csv(os.path.join(dir_fif, f'{pID}{event_fn_suffix}'))
            # treat '.' as missing in 'IA_ID'
            events['IA_ID'] = events['IA_ID'].replace('.', np.nan).fillna('-1').astype(int)
            events['eeg_sample'] = events['eeg_sample'].astype(float).astype(int)
            # replace Fixation_R reparsed with Fixation_R
            events['event_type'] = events['event_type'].replace('Fixation_R-reparsed','Fixation_R')
            events['identifier'] = events['identifier'].fillna('') # some are NaN
            events['task'] = events['task'].fillna('none') # some are NaN
            events['event_type'] = events['event_type'].fillna('other') # some are NaN
            events = events.drop_duplicates(subset=['latency_sec','description'])
            beh_df_i = beh_df[beh_df['ParticipantID']==pID]
            beh_df_i['identifier'] = beh_df_i['Text'].astype(str) + (beh_df_i['PageNum']-1).astype(str)
            # merge lexical properties to events by IA_ID, which needs to be forced to be a string formatted as an integer not a float like 1.0
            events = events.merge(ia_df, how='left')
            events = events.merge(beh_df_i, how='left')
            events['task+type'] = events['task'] + '/' + events['event_type']
            # make annotations from events
            annot_all = mne.Annotations(onset=events['latency_sec'], duration=events['duration_sec'], description=events['task+type'])
            EEG.set_annotations(annot_all)

            ##### select only reading events & crop (removes some noisy break intervals as a bonus)
            events = events[events['task']=='reading']
            # tmin = max([0, events['latency_sec'].min()-60])
            # tmax = min([EEG.times[-1],events['latency_sec'].max()+60])
            # EEG.crop(tmin=tmin, tmax=tmax)
            # events['latency_sec'] = events['latency_sec']-tmin
            # events['eeg_sample'] = (events['latency_sec']*EEG.info['sfreq']).round().astype(int)
            # events=events[(events['latency_sec']>=EEG.times[0]) & (events['latency_sec']<=EEG.times[-1])]

            ##### apply preprocessing to EEG (interp bads and reref alraedy done)
            EEG.filter(0.1, 40)
            # resample to 100 Hz
            # EEG.resample(100)
            ### resampling raw data is not recommended due to event timing jitter - see https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.resample
            # # resample eveents: EEG sample needs to be recalculated. Use rounding as this is what events_from_annotations does
            # events['eeg_index'] = np.searchsorted(EEG.times, events['latency_sec']) # might be off by one from orig eeg sample number... 

            ##### select only reading fixations and remove duplicates
            fixations = events[events['event_type']=='Fixation_R']
            # drop nin-IA fixations
            fixations = fixations[fixations['IA_ID']!=-1]
            # drop  duplicates on eeg sample
            dup_fixations = fixations[fixations.duplicated(subset='eeg_sample', keep=False)]['task+type']
            fixations = fixations.drop_duplicates(subset='eeg_sample', keep='first')
            fixations = fixations.set_index('eeg_sample')
            # make imputations for missing values.
            # FOr lexical variables use mean over STIMULUS set not ove rfixaitons/obs so it is the same for all ppts
            fixations['log_word_freq'] = fixations['log_word_freq'].fillna(ia_df['log_word_freq'].mean())
            fixations['surprisal'] = fixations['surprisal'].fillna(ia_df['surprisal'].mean())
            fixations['relative_word_position'] = fixations['relative_word_position'].fillna(ia_df['relative_word_position'].mean())
            fixations['INBOUND_SAC_AMPLITUDE'] = fixations['INBOUND_SAC_AMPLITUDE'].fillna(fixations['INBOUND_SAC_AMPLITUDE'].mean()) # probably better to use some avg over whole datast? 

            annot_fix = mne.Annotations(onset=fixations['latency_sec'], duration=fixations['duration_sec'], description=fixations['task+type'])
            EEG.set_annotations(annot_fix)
            trl_fix, trldict_fix = mne.events_from_annotations(EEG, regexp='.*Fixation_R')

            ##### MW 
            fixations['MW'] = fixations['MW'].fillna(-1).astype(int) # third condition coded as -1 for unknown
            # expand to dummy coded cols, one for MW=0 one for MW=1 (intercept is MW=-1)
            fixations['MW=0'] = (fixations['MW']==0).astype(int)
            fixations['MW=1'] = (fixations['MW']==1).astype(int)
            # # fixations['task+type+MW'] = fixations['task+type'] + '/MW=' + fixations['MW'].astype(str)
            # annot_fix = mne.Annotations(
            #     onset=fixations['latency_sec'], 
            #     duration=fixations['duration_sec'], 
            #     description=fixations['task']) # I.e. just intercept of FRP here, rest are in covaraiates
            # EEG.set_annotations(annot_fix)
            # trl_fix, trldict_fix = mne.events_from_annotations(EEG)

            ##### covariates
            #  use latencies in trl to look up covariates in events
            lexical_covariates = fixations.loc[trl_fix[:,0],[ 'surprisal', 'log_word_freq', 'relative_word_position']].apply(lambda x: (x-x.mean())/x.std(), axis=0) # zscore covariates
            gaze_covariates = fixations.loc[trl_fix[:,0],[ 'INBOUND_SAC_AMPLITUDE']].apply(lambda x: (x-x.mean())/x.std(), axis=0) # zscore covariates#.fillna(0)
            cognitive_covariates = fixations.loc[trl_fix[:,0],['MW=0','MW=1']]
            covariates = pd.concat([lexical_covariates, gaze_covariates, cognitive_covariates], axis=1)

            ##### covariates
            # separate lexical covariates for MW and no MW fixations so we can look at interaction
            for c in lexical_covariates.columns:
                for mw in [0,1]:
                    covariates[f'{c}_MW={mw}'] = covariates[c]*fixations[f'MW={mw}']
                    covariates[f'{c}_MW={mw}'] = covariates[f'{c}_MW={mw}'].fillna(ia_df[c].mean()) # default" vlaue of covariates is mean over materials
                # covariates.drop(columns=c, inplace=True)
            ##### model
            tmin, tmax = -0.3, 1
            loglevelwas = mne.set_log_level('WARNING', return_old_level=True)
            X, regressor_indices, rERP, stats = linear_regression_raw(EEG, 
                events=trl_fix, event_id=trldict_fix, 
                tmin=tmin, tmax=tmax, 
                reject={'eeg': 120e-6}, # uV, as in DImigen Ehinger 2019
                tstep=1,
                decim=10, #TODO: replace w 1 when finalized
                covariates=covariates, solver=partial(ridge_solver,alpha=1000)
            )

            ##### plot contrast between MW and no MW for main effect 
            fig=rERP['reading/Fixation_R'].plot()
            fig.savefig(os.path.join(dir_out, f'{pID}_FRP_butterfly.png'))
            rERP['FRP_MW=0'] = mne.combine_evoked([rERP['MW=0'], rERP['reading/Fixation_R']], weights=[1, 1])
            rERP['FRP_MW=1'] = mne.combine_evoked([rERP['MW=1'], rERP['reading/Fixation_R']], weights=[1, 1])
            plot_conds = [
                ['FRP_MW=0','FRP_MW=1'],
                ['surprisal','log_word_freq','relative_word_position'],
                ['surprisal_MW=0','surprisal_MW=1'],
            ]
            fig, ax = plt.subplots(len(plot_conds), 1,figsize=(12, 9))
            for i,cc in enumerate(plot_conds):
            # rERP_group = mne.grand_average(rERP_ALL)
                plotdict = {k:rERP[k] for k in cc}
                mne.viz.plot_compare_evokeds(plotdict, picks='CPz', axes=ax[i] )
            fig.savefig(os.path.join(dir_out, f'{pID}_FRP_effects.png'))

            ##### save regression erps
            mne.write_evokeds(os.path.join(dir_out, f'{pID}_rERP-evk.fif'), [ev for ev in rERP.values()], overwrite=True)
            # append to list of all subjects
            rERP_ALL.append(rERP)
        except Exception as e:
            print(f'Error in {pID}: {e}')
            continue

#%% read in already processed data
pIDs = [re.findall(r'EML1_\d{3}', f)[0] for f in os.listdir(dir_out) if f.endswith('_rERP-evk.fif')]
rERP_list = []
for pID in pIDs:
    rERP = mne.read_evokeds(os.path.join(dir_out, f'{pID}_rERP-evk.fif'))
    print(rERP[0].ch_names)
    rERP_list.append(rERP)
# group average and stats
#%%
# reformat group results to a dict of condition keys and values is a list of evokeds one from each subject
rERP_ALL = {}
channels = ['CPz', 'FCz', 'AFF5h', 'AFF6h', 'CCP5h', 'CCP6h', 'PPO9h', 'PPO10h']
cond_combinations = {
    'FRP': ['reading/Fixation_R'],
    'FRP_MW=0': ['reading/Fixation_R','MW=0'],
    'FRP_MW=1': ['reading/Fixation_R','MW=1'],
}
condnames = {}
for s in rERP_list:
    # refformat to dict of conditions
    s={evk.comment:evk for evk in s}
    for cond,c in s.items():
        condnames[cond] = cond
        # baseline correct
        c=c.apply_baseline((-.1, 0))
        # # downsample to 100Hz
        # c.resample(100)
        # check it contains CPz channel and skip if not
        if 'CPz' not in c.ch_names:
            print(f'{s} does not contain CPz, skipping')
            continue
        if cond in rERP_ALL:
            rERP_ALL[cond].append(c)
        else:
            rERP_ALL[cond] = [c]
    # combo conditions using mne.combine_evoked
    for cc, clist in cond_combinations.items():
        res = mne.combine_evoked([s[ci] for ci in clist], weights=[1 for ci in clist])
        if cc in rERP_ALL:
            rERP_ALL[cc].append(res)
        else:
            rERP_ALL[cc] = [res]
#%% equalize channels 
for c in rERP_ALL:
    rERP_ALL[c]=mne.equalize_channels(rERP_ALL[c])

#%% combo conditions have annopying long names
condnames.update({k: ' + '.join([ vi for vi in v]) for k,v in cond_combinations.items()})

plot_conds = [
                ['FRP_MW=0','FRP_MW=1'],
                ['surprisal','log_word_freq','relative_word_position'],
                ['surprisal_MW=0','surprisal_MW=1'],
]
for cc in plot_conds:
# rERP_group = mne.grand_average(rERP_ALL)
    plotdict = {k:rERP_ALL[k] for k in cc}
    mne.viz.plot_compare_evokeds(plotdict, picks='CPz' )

#%%
def plot_cluster(clusters, times, ax):
    h=None
    for i_c, c in enumerate(clusters):
        c = c[0]
        if cluster_p_values[i_c] <= 0.05:
            h = ax.axvspan(times[c.start], times[c.stop - 1], color="r", alpha=0.3)
        else:
            ax.axvspan(times[c.start], times[c.stop - 1], color=(0.3, 0.3, 0.3), alpha=0.3)
    plt.plot(times, T_obs, "g")
    if h:
        ax.legend((h,), ("cluster p-value < 0.05",))
    ax.set_xlabel("time (ms)")
    ax.set_ylabel("f-values")
    return ax

# %% t test on contrasts
contrast_conds =  [ 
    # ['FRP_MW=0','FRP_MW=1'],
    #             ['surprisal_MW=0','surprisal_MW=1'],
                ['surprisal']
                ]
channels = ['CPz']
for cc in contrast_conds:
    if len(cc) == 1:
        x = [rERP.get_data(picks=channels) for rERP in rERP_ALL[cc[0]]]
        # make into array of shape (n_subjects, n_channels, n_times)
        x = np.array(x)
        T_obs, clusters, cluster_p_values, H0 = mne.stats.permutation_cluster_test(x, out_type='mask', n_permutations=1000, seed=42, tail=0)
        times = rERP_ALL[cc[0]][0].times
        fig, ax = plt.subplots()
        plot_cluster(clusters, times, ax)   
        # title
        ax.set_title(f'{cc[0]}')
    elif len(cc) == 2:
        # X is list of array, shape (n_observations, p[, q][, r])
        x1 = np.array([rERP.get_data(picks=channels) for rERP in rERP_ALL[cc[0]]])
        x2 = np.array([rERP.get_data(picks=channels) for rERP in rERP_ALL[cc[1]]])
        T_obs, clusters, cluster_p_values, H0 = mne.stats.permutation_cluster_test([x1, x2], out_type='mask', n_permutations=1000, seed=42, tail=0)
        if clusters:
            times = rERP_ALL[cc[0]][0].times
            fig, ax = plt.subplots()
            # plot_cluster(clusters, times, ax)   
            h=None
            for i_c, c in enumerate(clusters):
                if cluster_p_values[i_c] <= 0.05:
                    h = ax.axvspan(times[c.start], times[c.stop - 1], color="r", alpha=0.3)
                else:
                    ax.axvspan(times[c.start], times[c.stop - 1], color=(0.3, 0.3, 0.3), alpha=0.3)
            plt.plot(times, T_obs, "g")
            if h:
                ax.legend((h,), ("cluster p-value < 0.05",))
            ax.set_xlabel("time (ms)")
            ax.set_ylabel("f-values")

            # title
            ax.set_title(f'{cc[0]} vs {cc[1]}')

# %%
